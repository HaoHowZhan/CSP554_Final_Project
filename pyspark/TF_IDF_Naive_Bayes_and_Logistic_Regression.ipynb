{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/usr/hdp/2.6.5.0-292/spark2\")\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer , IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.mllib.clustering import LDA, LDAModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465160"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.read.csv('/user/maria_dev/data/newsarticles_article.csv', sep=',', escape='\"', header=True, \n",
    "               inferSchema=True, multiLine=True).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sqlContext.read.csv('/user/maria_dev/data/newsarticles_article.csv', sep=',', escape='\"', header=False, \n",
    "               inferSchema=True, multiLine=True)\n",
    "tag = sqlContext.read.csv('/user/maria_dev/data/tags.csv', sep=',',  header=True, inferSchema=True, multiLine=True).withColumnRenamed(\"article_id\\r\", \"article_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag.columns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.join(tag, data._c0 == tag.article_id )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df =df.na.drop(subset=['category_id','_c4','_c5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.sample(False, 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsplit = df2.randomSplit([1.0, 2.0],24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfsplit[0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfsplit[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = dfsplit[0].rdd.map(lambda x : str(x['_c4']) + str(x['_c5']))\n",
    "reviews_test = dfsplit[1].rdd.map(lambda x : str(x['_c4']) + str(x['_c5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“Bully Bandit” Suspected In 16th Bank Robbery**CHICAGO (STMW) -** The “Bully Bandit” is suspected of striking again Thursday \\nmorning in south suburban Riverside, in his fourth suspected bank robbery in the\\n past month after a year-and-a-half hiatus.\\n\\nHe is suspected of robbing a Bank of America branch at 3300 S. Harlem Ave.\\nabout 11:15 a.m., the FBI said. The man, who was wearing a dark or gray hooded\\nChicago Bears sweatshirt, threatened to hurt employees and left with an\\nunspecified amount of cash, authorities said. He implied he had a weapon but\\nnever showed one.\\n\\nThe man is also suspected of robbing three Chicago banks since Oct. 11. — more\\nthan a year and a half after being suspected of a robbery in May 2013, the FBI\\nsaid.\\n\\nThe FBI is offering a reward of up to $17,500 for information that leads to\\nthe identification and arrest of the robber.\\n\\nThe robber is dubbed “The Bully Bandit” because of the aggressive manner in\\nwhich he carries out his crimes, the FBI said. He has pushed customers out of\\nthe way to get to tellers, and spoken in a rude manner.\\n\\nHe has displayed a handgun on at least one occasion, although no injuries have\\nbeen reported in connection with the robberies, the FBI said.\\n\\nThe bandit is described as a 5-foot-7 to 5-foot-8 Hispanic man in his late 20s\\nor early 30s with a medium build, according to the FBI. He has black hair and\\nbrown eyes, and appears to have at least four gold-capped lower front teeth.\\n\\nHe typically covers the lower half of his face with a scarf, article of\\nclothing or dust mask, the FBI said. In the Nov. 5 robbery, witnesses noted\\npink paint smudges on his hands and the white hooded sweatshirt he was\\nwearing.\\n\\nHe is also suspected of the following bank robberies:\\n\\n— Nov. 28, 2012, North Community Bank branch in the 1600 block of West\\nChicago;\\n\\n— Dec. 6, 2012, Chase Bank branch in the 4400 block of West North;\\n\\n— Dec. 11, 2012, PNC Bank branch in the 6600 block of West Ogden in Berwyn;\\n\\n— Dec. 27, 2012, PNC Bank branch in the 6600 block of West Cermak in Berwyn;\\n\\n— Jan. 18, 2013, Plaza Bank branch in the 5600 block of West Belmont;\\n\\n— Jan. 29, 2013, Chase Bank branch in the 5600 block of West Belmont;\\n\\n— Feb. 11, 2013, Chase Bank branch in the 6500 block of West Cermak;\\n\\n— Feb. 15, 2013, Chase Bank branch in the 3300 block of West Belmont;\\n\\n— March 29, 2013, Plaza Bank branch in the 5600 block of West Belmont;\\n\\n— April 13, 2013, Chase Bank branch in the 2600 block of North Milwaukee;\\n\\n— May 2, 2013, Bank of America branch in the 3300 block of South Harlem in\\nRiverside.\\n\\n— Oct. 11, North Community Bank branch in the 1600 block of West Chicago;\\n\\n— Oct. 28, Chase Bank branch in the 6600 block of West North;\\n\\n— Nov. 5, Chase Bank branch in the 1900 block of West Division\\n\\nThe bandit is also suspected of robbing a customer at the teller counter of a\\nChase branch in the 4800 block of West Irving Park Road on Feb. 12, 2013, the\\nFBI said.\\n\\nAnyone with information should contact the FBI’s Chicago office at (312)\\n421-6700.\\n\\n![][1]\\n\\n   [1]: http://pixel.wp.com/b.gif?host=chicago.cbslocal.com&blog=15116062&post=6\\n02861&subd=cbschicago&ref=&feed=1\\n']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train.top(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/maria_dev/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/maria_dev/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "StopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenlize(doc):\n",
    "    import nltk, re\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.corpus import wordnet\n",
    "\n",
    "    r = re.compile(r'[\\w]+')\n",
    "    my_stopwords = nltk.corpus.stopwords.words('english')\n",
    "    porter = nltk.PorterStemmer()\n",
    "\n",
    "    newdoc = []\n",
    "    for word in nltk.regexp_tokenize(doc, r): \n",
    "        newWord = porter.stem(word.lower()) \n",
    "        if newWord in my_stopwords: \n",
    "            continue\n",
    "        tokenSynsets = wordnet.synsets(newWord)\n",
    "        newdoc.append(newWord if tokenSynsets == [] else tokenSynsets[0].lemma_names()[0])\n",
    "    return newdoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintokens = reviews_train.map( lambda doc: tokenlize(doc))\n",
    "testtokens = reviews_test.map( lambda doc: tokenlize(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import HashingTF\n",
    "hasingTF = HashingTF(2 ** 16)\n",
    "trainTf = hasingTF.transform(traintokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import IDF\n",
    "idf = IDF().fit(trainTf)\n",
    "trainTfidf = idf.transform(trainTf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "trainLabels = dfsplit[0].rdd.map(lambda x : x['category_id'])\n",
    "train = trainLabels.zip(trainTfidf).map(lambda pair : LabeledPoint(pair[0], pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import HashingTF\n",
    "testTf = hasingTF.transform(testtokens )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTfidf = idf.transform(testTf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLabels = dfsplit[1].rdd.map(lambda x : x['category_id'])\n",
    "test = testLabels.zip(testTfidf).map(lambda pair : LabeledPoint(pair[0], pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCount= test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes\n",
    "model = NaiveBayes.train(train, 0.1)\n",
    "print('model trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.843298634582\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabel = test.map(lambda p: (model.predict(p.features), p.label))\n",
    "accuracy = 1.0 * predictionAndLabel.filter(lambda x: x[0] == x[1]).count() / testCount\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained\n"
     ]
    }
   ],
   "source": [
    "from  pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "lrModel = LogisticRegressionWithLBFGS.train(train, iterations=10, numClasses=20) \n",
    "print('model trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.862897120454\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabel = test.map(lambda p: (lrModel.predict(p.features), p.label))\n",
    "accuracy = 1.0 * predictionAndLabel.filter(lambda x: x[0] == x[1]).count() / testCount\n",
    "print(accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
